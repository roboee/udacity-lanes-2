{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()\n",
    "img_size = (img.shape[1],img.shape[0])\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints,imgpoints,img_size,None,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a distortion correction to raw images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_undistort(img, mtx, dist):\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Debug distortion correction to raw images:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "images = glob.glob('../camera_cal/calibration1.jpg')\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    undistorted = cal_undistort(img, mtx, dist)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(undistorted)\n",
    "    ax2.set_title('Undistorted Image', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "\n",
    "plt.savefig('undistort_output_mine.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### close debug plots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "plt.close('all')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use color transforms, gradients, etc., to create a thresholded binary image."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def pipeline(img, s_thresh=(120, 255), sx_thresh=(20, 100)):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "\n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    binary = np.zeros_like(sxbinary)\n",
    "    binary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 255\n",
    "\n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 255\n",
    "    # Stack each channel\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "    return binary , color_binary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### test color, gradient transforms:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "test_images = glob.glob('../test_images/straight_lines2.jpg')\n",
    "for fname in test_images:\n",
    "    img = cv2.imread(fname)\n",
    "    undistorted = cal_undistort(img, mtx, dist)\n",
    "    result , colored_result = pipeline(undistorted)\n",
    "    plt.imshow(colored_result)\n",
    "    plt.savefig('straight_lines2_thresh.png')\n",
    "    im_undistorted_rgb = cv2.cvtColor(undistorted, cv2.COLOR_BGR2RGB)\n",
    "    im_distorted_rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(im_distorted_rgb)\n",
    "    ax1.set_title('Original Image', fontsize=40)\n",
    "    ax2.imshow(im_undistorted_rgb)\n",
    "    ax2.set_title('Undistorted Result', fontsize=40)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "plt.savefig('straight_lines2.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### close debug plots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "plt.close('all')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Apply a perspective transform to rectify binary image (\"birds-eye view\"):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### extract perspective transform pixels from straight road by double clicking image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def draw_circle(event,x,y,flags,param):\n",
    "    global mouseX,mouseY\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        cv2.circle(img,(x,y),4,(255,0,0),-1)\n",
    "        mouseX,mouseY = x,y\n",
    "img = cv2.imread(test_images[len(test_images)-1])\n",
    "undistorted = cal_undistort(img, mtx, dist)\n",
    "cv2.namedWindow('img')\n",
    "cv2.setMouseCallback('img',draw_circle)\n",
    "while(1):\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(20) & 0xFF\n",
    "    if k == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    elif k == ord('a'):\n",
    "        print(mouseX,mouseY)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Use hardcoded points from above to extract perspective transform"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "#these are my originals:\n",
    "p1=[550,464]\n",
    "p2=[743,461]\n",
    "p3=[1279,685]\n",
    "p4=[115,685]\n",
    "\n",
    "def get_perspective_matrix(p1,p2,p3,p4,undist):\n",
    "    src = np.float32([p1,p2,p3,p4])\n",
    "    #orig\n",
    "    dst = np.float32([[0,0],[undist.shape[1],0],[undist.shape[1],undist.shape[0]],[0,undist.shape[0]]])\n",
    "    print(dst)\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    return M"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### corners unwarp - changes perspective of image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def corners_unwarp(undist , M):\n",
    "    width,height,d = undist.shape\n",
    "    warped = cv2.warpPerspective(undist, M, (height,width), flags=cv2.INTER_LINEAR)\n",
    "    return warped"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "test warped perspective on straight line image:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[320.   0.]\n",
      " [320. 720.]\n",
      " [960. 720.]\n",
      " [960.   0.]]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(test_images[len(test_images)-1])\n",
    "im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "undist = cal_undistort(im_rgb, mtx, dist)\n",
    "cv2.circle(undist,(p1[0],p1[1]),4,(255,0,0),-1)\n",
    "cv2.circle(undist,(p2[0],p2[1]),4,(255,0,0),-1)\n",
    "cv2.circle(undist,(p3[0],p3[1]),4,(255,0,0),-1)\n",
    "cv2.circle(undist,(p4[0],p4[1]),4,(255,0,0),-1)\n",
    "perspective_M = get_perspective_matrix(p1,p2,p3,p4,undist)\n",
    "top_down  = corners_unwarp(undist,perspective_M)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(undist)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(top_down)\n",
    "ax2.set_title('Undistorted and Warped Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "plt.savefig('warped_straight_lines_mine.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "close debug plots:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "plt.close('all')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Detect lane pixels and fit to find the lane boundary."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test undistortion , perspectve transformation and thresholdin for lane pixels:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "test_images = glob.glob('../test_images/*.jpg')\n",
    "img = cv2.imread(test_images[len(test_images)-1])\n",
    "im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "undist = cal_undistort(im_rgb, mtx, dist)\n",
    "perspective_M = get_perspective_matrix(p1,p2,p3,p4,undist)\n",
    "for fname in test_images:\n",
    "    img = cv2.imread(fname)\n",
    "    undist = cal_undistort(img, mtx, dist)\n",
    "    top_down  = corners_unwarp(undist,perspective_M)\n",
    "    binary_warped , colored_result = pipeline(top_down)\n",
    "    top_down_rgb = cv2.cvtColor(top_down, cv2.COLOR_BGR2RGB)\n",
    "    f, (ax1, ax2 ) = plt.subplots(2, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1[0].imshow(top_down_rgb)\n",
    "    ax1[0].set_title('Original Image', fontsize=40)\n",
    "    ax2[0].imshow(result)\n",
    "    ax2[0].set_title('Pipeline Result', fontsize=40)\n",
    "    ax1[1].imshow(colored_result)\n",
    "    ax1[1].set_title('colored thresh Result', fontsize=40)\n",
    "    ax2[1].imshow(img)\n",
    "    ax2[1].set_title('Original', fontsize=40)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 80,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[320.   0.]\n",
      " [320. 720.]\n",
      " [960. 720.]\n",
      " [960.   0.]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "close debug plots:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.close('all')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Initial lane detection function (sliding windows histogram approach from course):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def find_lane_pixels_init(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    side_roi = 100\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,side_roi:binary_warped.shape[1]-side_roi], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 100\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = side_roi+leftx_base\n",
    "    rightx_current = side_roi+rightx_base\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        ### TO-DO: Find the four below boundaries of the window ###\n",
    "        win_xleft_low = leftx_current - margin  # Update this\n",
    "        win_xleft_high = leftx_current + margin  # Update this\n",
    "        win_xright_low = rightx_current - margin# Update this\n",
    "        win_xright_high = rightx_current + margin  # Update this\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        ### TO-DO: If you found > minpix pixels, recenter next window ###\n",
    "        win_nonzero = binary_warped[win_y_low:win_y_high,leftx_current-margin:leftx_current+margin].nonzero()\n",
    "        if ( len(good_left_inds) > minpix  ):\n",
    "            leftx_current = leftx_current-margin+np.int(np.mean(win_nonzero[1]))\n",
    "        win_nonzero=binary_warped[win_y_low:win_y_high,rightx_current-margin:rightx_current+margin].nonzero()\n",
    "        if ( len(good_right_inds) > minpix  ):\n",
    "            rightx_current = rightx_current-margin+np.int(np.mean(win_nonzero[1]))\n",
    "\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2)\n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2)\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test by fitting a polynomial to the lane pixels after sliding window histrogram detection:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leftfit params [-6.93871591e-05  4.86094218e-02  1.69402555e+02]\n",
      "rightfit params [1.17880484e-06 3.07352674e-02 1.01906051e+03]\n"
     ]
    }
   ],
   "source": [
    "def fit_init_polynomial_with_viz(binary_warped):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels_init(binary_warped)\n",
    "\n",
    "    ### TO-DO: Fit a second order polynomial to each using `np.polyfit` ###\n",
    "    left_fit_params = np.polyfit(lefty,leftx,2)\n",
    "    right_fit_params = np.polyfit(righty,rightx,2)\n",
    "    print(\"leftfit params\",left_fit_params)\n",
    "    print(\"rightfit params\",right_fit_params)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit_params[0]*ploty**2 + left_fit_params[1]*ploty + left_fit_params[2]\n",
    "        right_fitx = right_fit_params[0]*ploty**2 + right_fit_params[1]*ploty + right_fit_params[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "    return out_img\n",
    "\n",
    "\n",
    "out_img = fit_init_polynomial_with_viz(binary_warped)\n",
    "\n",
    "plt.imshow(out_img)\n",
    "plt.savefig('first_fit.jpg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fit polynmials to pixels from the detected lane lines"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def fit_poly(img_shape, leftx, lefty, rightx, righty):\n",
    "     ### TO-DO: Fit a second order polynomial to each with np.polyfit() ###\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    ### TO-DO: Calc both polynomials using ploty, left_fit and right_fit ###\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    return left_fitx, right_fitx, left_fit , right_fit , ploty"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Continous lane detection algo, takes pixels that are +- margin from previous iteration detected lane polynomial, in case not enought pixels are found initializes lane detection\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lane inds:  9474  left inds  30144\n",
      "success\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f4ab4c64208>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftx, lefty, rightx, righty, out_img = find_lane_pixels_init(binary_warped)\n",
    "left_fitx, right_fitx, left_fit , right_fit, ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "def search_around_poly(binary_warped , left_fit_params , right_fit_params ):\n",
    "    margin = 100\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    ### TO-DO: Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "\n",
    "    left_lane_inds = ((nonzerox > (left_fit_params[0]*(nonzeroy**2) + left_fit_params[1]*nonzeroy + left_fit_params[2] - margin)) &\n",
    "                      (nonzerox < (left_fit_params[0]*(nonzeroy**2) + left_fit_params[1]*nonzeroy + left_fit_params[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit_params[0]*(nonzeroy**2) + right_fit_params[1]*nonzeroy + right_fit_params[2] - margin)) &\n",
    "                       (nonzerox < (right_fit_params[0]*(nonzeroy**2) + right_fit_params[1]*nonzeroy + right_fit_params[2] + margin)))\n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    # Fit new polynomials\n",
    "    left_fitx, right_fitx, left_fit_params , right_fit_params , ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin,\n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin,\n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    # Plot the polynomial lines onto the image\n",
    "    #plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #plt.plot(right_fitx, ploty, color='yellow')\n",
    "    thresh = 100\n",
    "    success = False\n",
    "    print(\"lane inds: \" , sum(right_lane_inds) , \" left inds \",sum(left_lane_inds))\n",
    "    if sum(right_lane_inds) > thresh and sum(left_lane_inds) > thresh:\n",
    "        print(\"success\")\n",
    "        success = True\n",
    "    ## End visualization steps ##\n",
    "    return result , success , left_fitx, right_fitx , ploty , leftx , lefty , rightx , righty , left_fit_params , right_fit_params\n",
    "# Run image through the pipeline\n",
    "# Note that in your project, you'll also want to feed in the previous fits\n",
    "result , success , left_fitx, right_fitx , ploty , leftx , lefty , rightx , righty , left_fit_params , right_fit_params = search_around_poly(binary_warped , left_fit , right_fit)\n",
    "# View your output\n",
    "plt.imshow(result)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Approximate real curvature from detected lane pixels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def measure_curvature_real(lefty,leftx,righty,rightx,img_shape):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    '''\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    left_fit = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0])\n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "\n",
    "    # Calculation of R_curve (radius of curvature)\n",
    "    left_curverad = ((1 + (2*left_fit[0]*y_eval*ym_per_pix + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*y_eval*ym_per_pix + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "\n",
    "    return left_curverad, right_curverad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Full process of lane detections, saves previous iteration lane polynomials and takes care of visualization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                                                              \u001B[A\u001B[A"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_image(image):\n",
    "    undistorted_image = cal_undistort(image, mtx, dist)\n",
    "    top_down  = corners_unwarp(undistorted_image,perspective_M)\n",
    "    binary_warped , colored_result = pipeline(top_down)\n",
    "    #print(\"search track: left fit\", process_image.left_fit_params , \" right fit \" , process_image.right_fit_params)\n",
    "    result , success , left_fitx, right_fitx , ploty , leftx , lefty , rightx , righty , process_image.left_fit_params , process_image.right_fit_params = search_around_poly(binary_warped , process_image.left_fit_params , process_image.right_fit_params )\n",
    "    if not success:\n",
    "        leftx, lefty, rightx, righty, out_img = find_lane_pixels_init(binary_warped)\n",
    "        left_fitx, right_fitx, process_image.left_fit_params , process_image.right_fit_params, ploty = fit_poly(binary_warped.shape, leftx, lefty, rightx, righty)\n",
    "        print(\"after track: left fit\", process_image.left_fit_params , \" right fit \" , process_image.right_fit_params)\n",
    "    left_curverad, right_curverad = measure_curvature_real(lefty,leftx,righty,rightx,top_down.shape)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    curvature_info_string = \"left curve is {} and right is {} m\".format(left_curverad, right_curverad)\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    center_pic = top_down.shape[1]\n",
    "    meters_from_mid = (((rightx[len(rightx)-1]+leftx[len(leftx)-1])/2)-(center_pic/2))*xm_per_pix\n",
    "    dist_from_center_string = \"dist from center is {} m\".format(meters_from_mid)\n",
    "    cv2.putText(undistorted_image, curvature_info_string, (10,30), font, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(undistorted_image, dist_from_center_string, (10,60), font, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    window_img = np.zeros_like(image)\n",
    "    binary_mask = np.zeros_like(binary_warped)\n",
    "    lane_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    lane_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx,ploty])))])\n",
    "    lane_pts = np.hstack((lane_left, lane_right))\n",
    "    cv2.fillPoly(window_img, np.int_([lane_pts]), (0,255, 0))\n",
    "    binary_mask[lefty, leftx] = 255\n",
    "    binary_mask[righty, rightx] = 100\n",
    "    orig_perspective_binary_img = corners_unwarp(window_img,inv_perspective_M)\n",
    "    orig_perspective_binary_mask = cv2.warpPerspective(binary_mask, inv_perspective_M, (binary_mask.shape[1],binary_mask.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    #cv2.imshow(\"result top down\",result)\n",
    "    #cv2.waitKey(1)\n",
    "    result = cv2.addWeighted(undistorted_image, 1.0, orig_perspective_binary_img, 0.3, 0)\n",
    "    #print(\"shape \" , orig_perspective_binary_mask.shape , \" orig mask \" , binary_mask.shape)\n",
    "    result[orig_perspective_binary_mask==255]=[255,0,0]\n",
    "    result[orig_perspective_binary_mask==100]=[0,0,255]\n",
    "    cv2.imshow(\"movie\",result)\n",
    "    cv2.waitKey(1)\n",
    "    return result\n",
    "process_image.right_fit_params = [0,0,0]\n",
    "process_image.left_fit_params = [0,0,0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lane inds:  249  left inds  249\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "result = process_image(img)\n",
    "result_rgb = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(result_rgb)\n",
    "plt.savefig('full_vis.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r\n",
      "\u001B[A                                                          \n",
      "\n",
      "t:  87%|████████▋ | 423/485 [1:19:47<00:11,  5.37it/s, now=None]\n",
      "t:  16%|█▌        | 76/485 [00:38<01:16,  5.36it/s, now=None]\u001B[A\n",
      "\n",
      "                                                                A\u001B[A\r\n",
      "\u001B[A                                                          \n",
      "\n",
      "t:  87%|████████▋ | 423/485 [1:19:47<00:11,  5.37it/s, now=None]\n",
      "t:  16%|█▌        | 76/485 [00:38<01:16,  5.36it/s, now=None]\u001B[A\n",
      "\n",
      "t:   3%|▎         | 39/1260 [00:15<05:52,  3.47it/s, now=None]\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   0%|          | 0/1260 [00:00<?, ?it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   0%|          | 2/1260 [00:00<03:41,  5.67it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   0%|          | 3/1260 [00:00<04:32,  4.61it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   0%|          | 4/1260 [00:00<05:03,  4.14it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   0%|          | 5/1260 [00:01<05:24,  3.87it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   0%|          | 6/1260 [00:01<05:37,  3.72it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   1%|          | 7/1260 [00:01<05:48,  3.59it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   1%|          | 8/1260 [00:02<05:54,  3.53it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   1%|          | 9/1260 [00:02<06:09,  3.39it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   1%|          | 10/1260 [00:02<06:19,  3.30it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   1%|          | 11/1260 [00:03<06:25,  3.24it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   1%|          | 12/1260 [00:03<06:24,  3.25it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   1%|          | 13/1260 [00:03<06:23,  3.25it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   1%|          | 14/1260 [00:04<06:33,  3.17it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   1%|          | 15/1260 [00:04<06:32,  3.17it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   1%|▏         | 16/1260 [00:04<06:25,  3.23it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   1%|▏         | 17/1260 [00:04<06:21,  3.26it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   1%|▏         | 18/1260 [00:05<06:14,  3.32it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   2%|▏         | 19/1260 [00:05<06:11,  3.34it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   2%|▏         | 20/1260 [00:05<06:07,  3.38it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   2%|▏         | 21/1260 [00:06<06:03,  3.40it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   2%|▏         | 22/1260 [00:06<06:14,  3.31it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   2%|▏         | 23/1260 [00:06<06:16,  3.28it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   2%|▏         | 24/1260 [00:07<06:13,  3.31it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   2%|▏         | 25/1260 [00:07<06:08,  3.35it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   2%|▏         | 26/1260 [00:07<06:03,  3.40it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   2%|▏         | 27/1260 [00:07<06:04,  3.39it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   2%|▏         | 28/1260 [00:08<06:02,  3.40it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   2%|▏         | 29/1260 [00:08<06:05,  3.37it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   2%|▏         | 30/1260 [00:08<05:57,  3.44it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   2%|▏         | 31/1260 [00:09<05:51,  3.50it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   3%|▎         | 32/1260 [00:09<05:47,  3.53it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   3%|▎         | 33/1260 [00:09<05:42,  3.58it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   3%|▎         | 34/1260 [00:09<05:45,  3.55it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   3%|▎         | 35/1260 [00:10<05:49,  3.50it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   3%|▎         | 36/1260 [00:10<05:50,  3.49it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   3%|▎         | 37/1260 [00:10<05:48,  3.51it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   3%|▎         | 38/1260 [00:11<05:44,  3.55it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   3%|▎         | 39/1260 [00:11<05:43,  3.56it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   3%|▎         | 40/1260 [00:11<05:41,  3.57it/s, now=None]\u001B[A\u001B[A\u001B[A\n",
      "\n",
      "\n",
      "t:   3%|▎         | 41/1260 [00:11<05:38,  3.60it/s, now=None]\u001B[A\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lane inds:  26404  left inds  26404\n",
      "success\n",
      "Moviepy - Building video ../output_images/challenge.mp4.\n",
      "Moviepy - Writing video ../output_images/challenge.mp4\n",
      "\n",
      "lane inds:  26412  left inds  26412\n",
      "success\n",
      "lane inds:  25608  left inds  25608\n",
      "success\n",
      "lane inds:  25055  left inds  25055\n",
      "success\n",
      "lane inds:  24615  left inds  24615\n",
      "success\n",
      "lane inds:  24251  left inds  24251\n",
      "success\n",
      "lane inds:  24013  left inds  24013\n",
      "success\n",
      "lane inds:  23833  left inds  23833\n",
      "success\n",
      "lane inds:  25266  left inds  25266\n",
      "success\n",
      "lane inds:  25560  left inds  25560\n",
      "success\n",
      "lane inds:  25903  left inds  25903\n",
      "success\n",
      "lane inds:  25010  left inds  25010\n",
      "success\n",
      "lane inds:  24947  left inds  24947\n",
      "success\n",
      "lane inds:  26672  left inds  26672\n",
      "success\n",
      "lane inds:  26120  left inds  26120\n",
      "success\n",
      "lane inds:  25425  left inds  25425\n",
      "success\n",
      "lane inds:  24659  left inds  24659\n",
      "success\n",
      "lane inds:  23823  left inds  23823\n",
      "success\n",
      "lane inds:  24121  left inds  24121\n",
      "success\n",
      "lane inds:  23844  left inds  23844\n",
      "success\n",
      "lane inds:  24117  left inds  24117\n",
      "success\n",
      "lane inds:  26186  left inds  26186\n",
      "success\n",
      "lane inds:  25493  left inds  25493\n",
      "success\n",
      "lane inds:  25592  left inds  25592\n",
      "success\n",
      "lane inds:  25331  left inds  25331\n",
      "success\n",
      "lane inds:  25057  left inds  25057\n",
      "success\n",
      "lane inds:  25473  left inds  25473\n",
      "success\n",
      "lane inds:  25523  left inds  25523\n",
      "success\n",
      "lane inds:  25622  left inds  25622\n",
      "success\n",
      "lane inds:  24820  left inds  24820\n",
      "success\n",
      "lane inds:  24317  left inds  24317\n",
      "success\n",
      "lane inds:  24093  left inds  24093\n",
      "success\n",
      "lane inds:  23480  left inds  23480\n",
      "success\n",
      "lane inds:  24560  left inds  24560\n",
      "success\n",
      "lane inds:  25375  left inds  25375\n",
      "success\n",
      "lane inds:  25034  left inds  25034\n",
      "success\n",
      "lane inds:  24227  left inds  24227\n",
      "success\n",
      "lane inds:  24037  left inds  24037\n",
      "success\n",
      "lane inds:  24452  left inds  24452\n",
      "success\n",
      "lane inds:  24368  left inds  24368\n",
      "success\n",
      "lane inds:  23816  left inds  23816\n",
      "success\n",
      "lane inds:  22980  left inds  22980\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<timed eval>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n",
      "\u001B[0;32m<decorator-gen-180>\u001B[0m in \u001B[0;36mwrite_videofile\u001B[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/moviepy/decorators.py\u001B[0m in \u001B[0;36mrequires_duration\u001B[0;34m(f, clip, *a, **k)\u001B[0m\n\u001B[1;32m     52\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Attribute 'duration' not set\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclip\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     55\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<decorator-gen-179>\u001B[0m in \u001B[0;36mwrite_videofile\u001B[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/moviepy/decorators.py\u001B[0m in \u001B[0;36muse_clip_fps_by_default\u001B[0;34m(f, clip, *a, **k)\u001B[0m\n\u001B[1;32m    133\u001B[0m              for (k,v) in k.items()}\n\u001B[1;32m    134\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 135\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclip\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mnew_a\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mnew_kw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<decorator-gen-178>\u001B[0m in \u001B[0;36mwrite_videofile\u001B[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/moviepy/decorators.py\u001B[0m in \u001B[0;36mconvert_masks_to_RGB\u001B[0;34m(f, clip, *a, **k)\u001B[0m\n\u001B[1;32m     20\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mclip\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mismask\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m         \u001B[0mclip\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mclip\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_RGB\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 22\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclip\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;34m@\u001B[0m\u001B[0mdecorator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecorator\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/moviepy/video/VideoClip.py\u001B[0m in \u001B[0;36mwrite_videofile\u001B[0;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001B[0m\n\u001B[1;32m    305\u001B[0m                            \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthreads\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mthreads\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    306\u001B[0m                            \u001B[0mffmpeg_params\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mffmpeg_params\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 307\u001B[0;31m                            logger=logger)\n\u001B[0m\u001B[1;32m    308\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    309\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mremove_temp\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mmake_audio\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/moviepy/video/io/ffmpeg_writer.py\u001B[0m in \u001B[0;36mffmpeg_write_video\u001B[0;34m(clip, filename, fps, codec, bitrate, preset, withmask, write_logfile, audiofile, verbose, threads, ffmpeg_params, logger)\u001B[0m\n\u001B[1;32m    219\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    220\u001B[0m         for t,frame in clip.iter_frames(logger=logger, with_times=True,\n\u001B[0;32m--> 221\u001B[0;31m                                         fps=fps, dtype=\"uint8\"):\n\u001B[0m\u001B[1;32m    222\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mwithmask\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    223\u001B[0m                 \u001B[0mmask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m255\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mclip\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_frame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/moviepy/Clip.py\u001B[0m in \u001B[0;36miter_frames\u001B[0;34m(self, fps, with_times, logger, dtype)\u001B[0m\n\u001B[1;32m    470\u001B[0m         \u001B[0mlogger\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mproglog\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdefault_bar_logger\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogger\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    471\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miter_bar\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mduration\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1.0\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0mfps\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 472\u001B[0;31m             \u001B[0mframe\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_frame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    473\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    474\u001B[0m                 \u001B[0mframe\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<decorator-gen-136>\u001B[0m in \u001B[0;36mget_frame\u001B[0;34m(self, t)\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/moviepy/decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(f, *a, **kw)\u001B[0m\n\u001B[1;32m     87\u001B[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001B[1;32m     88\u001B[0m                  for (k,v) in kw.items()}\n\u001B[0;32m---> 89\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mnew_a\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mnew_kw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     90\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdecorator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecorator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwrapper\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     91\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/moviepy/Clip.py\u001B[0m in \u001B[0;36mget_frame\u001B[0;34m(self, t)\u001B[0m\n\u001B[1;32m     91\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     92\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 93\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmake_frame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     94\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     95\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfun\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mapply_to\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeep_duration\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/moviepy/Clip.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m    134\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    135\u001B[0m         \u001B[0;31m#mf = copy(self.make_frame)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 136\u001B[0;31m         \u001B[0mnewclip\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_make_frame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mfun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_frame\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    137\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    138\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mkeep_duration\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/moviepy/video/VideoClip.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(gf, t)\u001B[0m\n\u001B[1;32m    488\u001B[0m         \"\"\"\n\u001B[1;32m    489\u001B[0m         \u001B[0mapply_to\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mapply_to\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 490\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mgf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mimage_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mapply_to\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    491\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    492\u001B[0m     \u001B[0;31m# --------------------------------------------------------------\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-63-315caeab5751>\u001B[0m in \u001B[0;36mprocess_image\u001B[0;34m(image)\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0mbinary_warped\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0mcolored_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpipeline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtop_down\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;31m#print(\"search track: left fit\", process_image.left_fit_params , \" right fit \" , process_image.right_fit_params)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m     \u001B[0mresult\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0msuccess\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0mleft_fitx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mright_fitx\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0mploty\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0mleftx\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0mlefty\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0mrightx\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0mrighty\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0mprocess_image\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mleft_fit_params\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0mprocess_image\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mright_fit_params\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msearch_around_poly\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbinary_warped\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0mprocess_image\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mleft_fit_params\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0mprocess_image\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mright_fit_params\u001B[0m \u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0msuccess\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m         \u001B[0mleftx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlefty\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrightx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrighty\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout_img\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfind_lane_pixels_init\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbinary_warped\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-61-95530cd7658f>\u001B[0m in \u001B[0;36msearch_around_poly\u001B[0;34m(binary_warped, left_fit_params, right_fit_params)\u001B[0m\n\u001B[1;32m     49\u001B[0m     \u001B[0msuccess\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"lane inds: \"\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mright_lane_inds\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0;34m\" left inds \"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mleft_lane_inds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m     \u001B[0;32mif\u001B[0m \u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mright_lane_inds\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0mthresh\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mleft_lane_inds\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0mthresh\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"success\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m         \u001B[0msuccess\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "inv_perspective_M = np.linalg.pinv(perspective_M)\n",
    "from moviepy.editor import VideoFileClip\n",
    "challenge_output = '../output_images/challenge.mp4'\n",
    "clip3 = VideoFileClip('../project_video.mp4')\n",
    "challenge_clip = clip3.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "pycharm-e1c0e963",
   "language": "python",
   "display_name": "PyCharm (pythonProject)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}